{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ナイーブベイズ分類器による割り当て"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def read_fasta(file_path):\n",
    "    \"\"\"FASTAファイルを読み込む関数\"\"\"\n",
    "    ids = []\n",
    "    sequences = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        while True:\n",
    "            id_line = f.readline().strip()\n",
    "            seq_line = f.readline().strip()\n",
    "            if not id_line:  # EOF\n",
    "                break\n",
    "            ids.append(id_line[1:])  # '>'を除去\n",
    "            sequences.append(seq_line)\n",
    "    return pd.DataFrame({'#OTU ID': ids, 'sequence': sequences})\n",
    "\n",
    "\n",
    "\n",
    "taxonomy_path = os.path.join('.', 'taxonomy.tsv')\n",
    "feature_table_path = os.path.join('.', 'feature-table.tsv')\n",
    "fasta_path = os.path.join('.', 'dna-sequences.fasta')\n",
    "file_path = os.path.join('.', 'ASV0.xlsx')\n",
    "\n",
    "# tsvファイルとfastaファイルを読み込みます\n",
    "taxonomy_df = pd.read_csv(taxonomy_path, sep='\\t', comment='#')\n",
    "\n",
    "# tsvファイルの2行目（0-indexedなので1を指定）を読み込み、カラム名として使用します\n",
    "columns = pd.read_csv(feature_table_path, sep='\\t', skiprows=1, nrows=0).columns.tolist()\n",
    "# skiprowsを使って最初の2行をスキップし、namesを使ってカラム名を指定します\n",
    "feature_table_df = pd.read_csv(feature_table_path, sep='\\t', skiprows=2, names=columns)\n",
    "\n",
    "fasta_df = read_fasta(fasta_path)\n",
    "\n",
    "# Feature ID でデータフレームをマージします\n",
    "merged_df = pd.merge(taxonomy_df, feature_table_df, left_on='Feature ID', right_on='#OTU ID')\n",
    "merged_df = pd.merge(merged_df, fasta_df, on='#OTU ID')\n",
    "\n",
    "# Feature ID を削除し、OTU ID を ASV にリネーム\n",
    "merged_df = merged_df.drop(columns='Feature ID')\n",
    "merged_df = merged_df.rename(columns={'#OTU ID': 'ASV_ID', 'sequence': 'Representative sequence'})\n",
    "\n",
    "# Taxonを';'でスプリットし、Order, Family, Genus, Speciesを抽出\n",
    "taxon_splitted = merged_df['Taxon'].str.split(';', expand=True)\n",
    "\n",
    "merged_df['Order'] = taxon_splitted[3].str.split('__', expand=True)[1]\n",
    "merged_df['Family'] = taxon_splitted[4].str.split('__', expand=True)[1]\n",
    "merged_df['Genus'] = taxon_splitted[5].str.split('__', expand=True)[1]\n",
    "merged_df['Species'] = taxon_splitted[6].str.split('__', expand=True)[1]\n",
    "merged_df['Species'] = merged_df['Species'].replace('NA', '')\n",
    "\n",
    "merged_df = merged_df.drop(columns=['Taxon'])\n",
    "\n",
    "# Speciesカラムの学名を２分法に統一する関数\n",
    "def unify_species_name(name):\n",
    "    if name is None:\n",
    "        return None\n",
    "    parts = name.split()\n",
    "    if len(parts) > 2:\n",
    "        return ' '.join(parts[:2])\n",
    "    return name\n",
    "\n",
    "\n",
    "# Speciesカラムの値を更新\n",
    "merged_df['Species'] = merged_df['Species'].apply(unify_species_name)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blast検索の５つの結果をマージする\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('blast_results.tsv', sep='\\t', header=None)\n",
    "\n",
    "df = df.iloc[:,[0,2,12,14]]\n",
    "\n",
    "df.columns = ['query_id', 'science_name', 'blast_score', 'c_rate']\n",
    "\n",
    "grouped = df.groupby('query_id').agg(list)\n",
    "\n",
    "grouped.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# 新しいカラム名を生成してデータを展開\n",
    "for col in ['science_name', 'blast_score', 'c_rate']:\n",
    "    for i in range(5):\n",
    "        grouped[f'{col}_{i+1}'] = grouped[col].apply(lambda x: x[i] if i < len(x) else None)\n",
    "        \n",
    "grouped.drop(['science_name', 'blast_score', 'c_rate'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "new_order = ['query_id']\n",
    "for i in range(1,6):\n",
    "    new_order.extend([f'science_name_{i}',f'c_rate_{i}',f'blast_score_{i}'])\n",
    "grouped = grouped[new_order]\n",
    "\n",
    "\n",
    "# ASV_IDとqseqidをキーカラムとして2つのデータフレームを連結\n",
    "merged_df = pd.merge(merged_df, grouped, left_on='ASV_ID', right_on='query_id', how='left')\n",
    "\n",
    "merged_df.drop(columns='query_id', inplace=True)\n",
    "\n",
    "merged_df.loc[merged_df['Species'] != '','Species'] = merged_df['Genus'] + ' ' + merged_df['Species']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#blast検索の結果から最も一致率等が高い生物種を抜き出し、Qimme2の結果と比較して採用する分類結果を格納する\n",
    "#閾値を調整するときは本セクションの15列目と35列目を調整する\n",
    "#途中経過ファイルを出力する\n",
    "import numpy as np\n",
    "\n",
    "def select_best_match(row):\n",
    "    best_match_name = None  # 正しく初期化\n",
    "    highest_c_rate = 0\n",
    "    highest_blast_score = 0\n",
    "    \n",
    "    for i in range(1, 5):\n",
    "        c_rate = row[f'c_rate_{i}']  # インデックスを i に修正\n",
    "        blast_score = row[f'blast_score_{i}']  # インデックスを i に修正\n",
    "        \n",
    "        if c_rate >= 98.7 and (c_rate > highest_c_rate or (c_rate == highest_c_rate and blast_score > highest_blast_score)):\n",
    "            highest_c_rate = c_rate\n",
    "            highest_blast_score = blast_score\n",
    "            best_match_name = row[f'science_name_{i}']\n",
    "    \n",
    "    return best_match_name, highest_c_rate, highest_blast_score\n",
    "\n",
    "# DataFrameの適用部分は変更なし\n",
    "merged_df[['best_match_name', 'best_match_c_rate', 'best_match_blast_score']] = merged_df.apply(\n",
    "    lambda row: pd.Series(select_best_match(row)),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "def compare_classifier(row):\n",
    "    if not pd.isna(row['best_match_name']):\n",
    "        if row['best_match_name'] != row['Species']:\n",
    "            return row['best_match_name']\n",
    "        else:\n",
    "            return row['Species']\n",
    "    else:\n",
    "        if row['Confidence'] >= 0.8:\n",
    "            return row['Species']\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "merged_df['Species_new'] = merged_df.apply(compare_classifier, axis=1)  \n",
    "\n",
    "merged_df.to_excel('temp_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Species_infoファイルを読み込む\n",
    "species_info_path = 'Species_info'\n",
    "species_df = pd.read_csv(species_info_path, header=None, names=['classification'])\n",
    "\n",
    "# 分類情報を個別のカラムに分割\n",
    "classification_columns = ['kingdom', 'phylum', 'class', 'order', 'family', 'genus', 'species']\n",
    "species_df[classification_columns] = species_df['classification'].str.split('; ', expand=True)\n",
    "\n",
    "# 不要な接頭辞を削除\n",
    "for col in classification_columns:\n",
    "    species_df[col] = species_df[col].str.replace(r'^[a-z]__','', regex=True)\n",
    "\n",
    "# 不要なカラムを削除\n",
    "species_df.drop('classification', axis=1, inplace=True)\n",
    "\n",
    "species_df['species'] = species_df['genus'] + ' ' + species_df['species']\n",
    "species_df = species_df.drop_duplicates(subset='species')\n",
    "\n",
    "\n",
    "# merged_dfのSpeciesカラムからGenusとSpeciesを抽出\n",
    "merged_df['Species_tmp'] = merged_df['Species'].str.split().str[1]\n",
    "merged_df['Genus_tmp'] = merged_df['Species'].str.split().str[0]\n",
    "merged_df['Species_tmp2'] = merged_df['Species_new'].str.split().str[1]\n",
    "merged_df['Genus_tmp2'] = merged_df['Species_new'].str.split().str[0]\n",
    "\n",
    "\n",
    "# ①〜⑤の操作を実行\n",
    "for idx, row in merged_df.iterrows():\n",
    "    genus_tmp2 = row['Genus_tmp2']\n",
    "    genus_tmp = row['Genus_tmp']\n",
    "    \n",
    "    # ②特になにもしません\n",
    "    if genus_tmp2 == genus_tmp:\n",
    "        continue\n",
    "    \n",
    "    # ③条件に当てはまる場合の操作\n",
    "    if pd.isna(genus_tmp2) and pd.notna(genus_tmp):\n",
    "        species = row['Species_new']\n",
    "        species_match = species_df[species_df['species'] == species]\n",
    "        if not species_match.empty:\n",
    "            merged_df.at[idx, 'Order'] = species_match['order'].values[0]\n",
    "            merged_df.at[idx, 'Family'] = species_match['family'].values[0]\n",
    "            merged_df.at[idx, 'Genus'] = species_match['genus'].values[0]\n",
    "    elif pd.isna(genus_tmp) and pd.notna(genus_tmp2):\n",
    "        species = row['Species_new']\n",
    "        species_match = species_df[species_df['species'] == species]\n",
    "        if not species_match.empty:\n",
    "            merged_df.at[idx, 'Order'] = species_match['order'].values[0]\n",
    "            merged_df.at[idx, 'Family'] = species_match['family'].values[0]\n",
    "            merged_df.at[idx, 'Genus'] = species_match['genus'].values[0]\n",
    "    elif pd.notna(genus_tmp2) and pd.notna(genus_tmp) and genus_tmp2 != genus_tmp:\n",
    "        species = row['Species_new']\n",
    "        species_match = species_df[species_df['species'] == species]\n",
    "        if not species_match.empty:\n",
    "            merged_df.at[idx, 'Order'] = species_match['order'].values[0]\n",
    "            merged_df.at[idx, 'Family'] = species_match['family'].values[0]\n",
    "            merged_df.at[idx, 'Genus'] = species_match['genus'].values[0]\n",
    "\n",
    "\n",
    "# 不要なカラムを削除\n",
    "merged_df.drop([\n",
    "    'Confidence',\n",
    "    'Species',\n",
    "    'science_name_1',\n",
    "    'c_rate_1',\n",
    "    'blast_score_1',\n",
    "    'science_name_2',\n",
    "    'c_rate_2',\n",
    "    'blast_score_2',\n",
    "    'science_name_3',\n",
    "    'c_rate_3',\n",
    "    'blast_score_3',\n",
    "    'science_name_4',\n",
    "    'c_rate_4',\n",
    "    'blast_score_4',\n",
    "    'science_name_5',\n",
    "    'c_rate_5',\n",
    "    'blast_score_5',\n",
    "    'best_match_name',\n",
    "    'best_match_c_rate',\n",
    "    'best_match_blast_score',\n",
    "    'Species_tmp',\n",
    "    'Genus_tmp',\n",
    "    'Species_tmp2',\n",
    "    'Genus_tmp2'\n",
    "], axis=1, inplace=True)\n",
    "\n",
    "# Species_newカラムをSpeciesにリネーム\n",
    "new_df = merged_df.rename(columns={'Species_new': 'Species'})\n",
    "\n",
    "# Excelファイルとして出力\n",
    "new_df.to_excel('output.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
